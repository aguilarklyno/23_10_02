{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "from scipy.optimize import minimize\n",
    "import pytz\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import seaborn as sns\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "import statsmodels.tsa.api as smt\n",
    "from copy import deepcopy\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import arma_order_select_ic\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import statsmodels.tools.eval_measures\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import time\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.dates import YearLocator, DateFormatter\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_excel(\"./RAW_DATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>DX-Y.NYB</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MET</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^TNX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>25.395000</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>84.699997</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>29.158445</td>\n",
       "      <td>49.269161</td>\n",
       "      <td>46.520000</td>\n",
       "      <td>2001.569946</td>\n",
       "      <td>2.600</td>\n",
       "      <td>12.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-28</td>\n",
       "      <td>25.264999</td>\n",
       "      <td>16.225000</td>\n",
       "      <td>402.152008</td>\n",
       "      <td>84.669998</td>\n",
       "      <td>1216.800049</td>\n",
       "      <td>29.288090</td>\n",
       "      <td>49.215687</td>\n",
       "      <td>47.060001</td>\n",
       "      <td>1994.290039</td>\n",
       "      <td>2.566</td>\n",
       "      <td>13.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>25.027500</td>\n",
       "      <td>16.091000</td>\n",
       "      <td>375.467010</td>\n",
       "      <td>85.589996</td>\n",
       "      <td>1217.500000</td>\n",
       "      <td>28.739098</td>\n",
       "      <td>48.048126</td>\n",
       "      <td>46.439999</td>\n",
       "      <td>1977.800049</td>\n",
       "      <td>2.491</td>\n",
       "      <td>15.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-12</td>\n",
       "      <td>24.905001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>330.079010</td>\n",
       "      <td>85.709999</td>\n",
       "      <td>1206.699951</td>\n",
       "      <td>28.788462</td>\n",
       "      <td>47.228165</td>\n",
       "      <td>46.090000</td>\n",
       "      <td>1964.819946</td>\n",
       "      <td>2.425</td>\n",
       "      <td>15.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-19</td>\n",
       "      <td>24.952499</td>\n",
       "      <td>15.322500</td>\n",
       "      <td>390.414001</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>1229.300049</td>\n",
       "      <td>26.587503</td>\n",
       "      <td>43.645275</td>\n",
       "      <td>43.650002</td>\n",
       "      <td>1874.739990</td>\n",
       "      <td>2.286</td>\n",
       "      <td>24.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>128.259995</td>\n",
       "      <td>27583.677734</td>\n",
       "      <td>106.080002</td>\n",
       "      <td>1849.500000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>61.900002</td>\n",
       "      <td>329.820007</td>\n",
       "      <td>4335.660156</td>\n",
       "      <td>4.797</td>\n",
       "      <td>17.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>178.720001</td>\n",
       "      <td>132.550003</td>\n",
       "      <td>28519.466797</td>\n",
       "      <td>106.239998</td>\n",
       "      <td>1921.099976</td>\n",
       "      <td>140.490005</td>\n",
       "      <td>63.349998</td>\n",
       "      <td>332.640015</td>\n",
       "      <td>4373.629883</td>\n",
       "      <td>4.712</td>\n",
       "      <td>17.209999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>126.559998</td>\n",
       "      <td>33086.234375</td>\n",
       "      <td>105.540001</td>\n",
       "      <td>1976.300049</td>\n",
       "      <td>137.899994</td>\n",
       "      <td>58.490002</td>\n",
       "      <td>329.320007</td>\n",
       "      <td>4217.040039</td>\n",
       "      <td>4.838</td>\n",
       "      <td>20.370001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>170.289993</td>\n",
       "      <td>132.710007</td>\n",
       "      <td>34502.363281</td>\n",
       "      <td>106.120003</td>\n",
       "      <td>1996.199951</td>\n",
       "      <td>125.750000</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>337.309998</td>\n",
       "      <td>4166.819824</td>\n",
       "      <td>4.875</td>\n",
       "      <td>19.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>179.229996</td>\n",
       "      <td>139.740005</td>\n",
       "      <td>35037.371094</td>\n",
       "      <td>105.220001</td>\n",
       "      <td>1981.599976</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>60.430000</td>\n",
       "      <td>356.529999</td>\n",
       "      <td>4365.979980</td>\n",
       "      <td>4.662</td>\n",
       "      <td>14.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        AAPL        AMZN       BTC-USD    DX-Y.NYB         GC=F  \\\n",
       "0   2014-09-21   25.395000   16.200001    457.334015   84.699997  1234.400024   \n",
       "1   2014-09-28   25.264999   16.225000    402.152008   84.669998  1216.800049   \n",
       "2   2014-10-05   25.027500   16.091000    375.467010   85.589996  1217.500000   \n",
       "3   2014-10-12   24.905001   16.110001    330.079010   85.709999  1206.699951   \n",
       "4   2014-10-19   24.952499   15.322500    390.414001   85.430000  1229.300049   \n",
       "..         ...         ...         ...           ...         ...          ...   \n",
       "473 2023-10-15  178.990005  128.259995  27583.677734  106.080002  1849.500000   \n",
       "474 2023-10-22  178.720001  132.550003  28519.466797  106.239998  1921.099976   \n",
       "475 2023-10-29  173.000000  126.559998  33086.234375  105.540001  1976.300049   \n",
       "476 2023-11-05  170.289993  132.710007  34502.363281  106.120003  1996.199951   \n",
       "477 2023-11-12  179.229996  139.740005  35037.371094  105.220001  1981.599976   \n",
       "\n",
       "           GOOG        MET        MSFT        ^GSPC   ^TNX       ^VIX  \n",
       "0     29.158445  49.269161   46.520000  2001.569946  2.600  12.650000  \n",
       "1     29.288090  49.215687   47.060001  1994.290039  2.566  13.690000  \n",
       "2     28.739098  48.048126   46.439999  1977.800049  2.491  15.980000  \n",
       "3     28.788462  47.228165   46.090000  1964.819946  2.425  15.460000  \n",
       "4     26.587503  43.645275   43.650002  1874.739990  2.286  24.639999  \n",
       "..          ...        ...         ...          ...    ...        ...  \n",
       "473  139.500000  61.900002  329.820007  4335.660156  4.797  17.700001  \n",
       "474  140.490005  63.349998  332.640015  4373.629883  4.712  17.209999  \n",
       "475  137.899994  58.490002  329.320007  4217.040039  4.838  20.370001  \n",
       "476  125.750000  59.419998  337.309998  4166.819824  4.875  19.750000  \n",
       "477  131.449997  60.430000  356.529999  4365.979980  4.662  14.890000  \n",
       "\n",
       "[478 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function]Making Portofolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficient_frontier(temp_data, selected):\n",
    "    # calculate daily and annual returns of the stocks\n",
    "    returns_monthly = temp_data.pct_change()\n",
    "    returns_annual = returns_monthly.mean() * 12\n",
    "\n",
    "    # get daily and covariance of returns of the stock\n",
    "    cov_monthly = returns_monthly.cov()\n",
    "    cov_annual = cov_monthly * 12\n",
    "\n",
    "    # 米国国債のリスクフリーレート\n",
    "    rf_rate = 0.04849\n",
    "\n",
    "    # empty lists to store returns, volatility and weights of imaginary portfolios\n",
    "    port_returns = []\n",
    "    port_volatility = []\n",
    "    sharpe_ratio = []\n",
    "    stock_weights = []\n",
    "\n",
    "    # set the number of combinations for imaginary portfolios\n",
    "    num_assets = len(selected)\n",
    "    num_portfolios = 5000\n",
    "\n",
    "    np.random.seed(101)\n",
    "\n",
    "    for single_portfolio in range(num_portfolios):\n",
    "        weights = np.random.random(num_assets)\n",
    "        weights /= np.sum(weights)\n",
    "        returns = np.dot(weights, returns_annual)\n",
    "        volatility = np.sqrt(np.dot(weights.T, np.dot(cov_annual, weights)))\n",
    "        sharpe = (returns - rf_rate) / volatility  # シャープレシオの計算を修正\n",
    "        sharpe_ratio.append(sharpe)\n",
    "        port_returns.append(returns)\n",
    "        port_volatility.append(volatility)\n",
    "        stock_weights.append(weights)\n",
    "\n",
    "    portfolio = {'Returns': port_returns,\n",
    "                'Volatility': port_volatility,\n",
    "                'Sharpe Ratio': sharpe_ratio}\n",
    "\n",
    "    for counter, symbol in enumerate(selected):\n",
    "        portfolio[symbol + ' Weight'] = [Weight[counter] for Weight in stock_weights]\n",
    "\n",
    "    df = pd.DataFrame(portfolio)\n",
    "    column_order = ['Returns', 'Volatility', 'Sharpe Ratio'] + [stock + ' Weight' for stock in selected]\n",
    "    df = df[column_order]\n",
    "\n",
    "    # 最大シャープレシオを持つポートフォリオを探す\n",
    "    max_sharpe = df['Sharpe Ratio'].max()\n",
    "    min_volatility = df['Volatility'].min()\n",
    "    sharpe_portfolio = df.loc[df['Sharpe Ratio'] == max_sharpe]\n",
    "    min_variance_port = df.loc[df['Volatility'] == min_volatility]\n",
    "\n",
    "    print(sharpe_portfolio.T)\n",
    "    print(min_variance_port.T)\n",
    "\n",
    "    df.plot.scatter(x='Volatility', y='Returns', c='Sharpe Ratio',\n",
    "                    cmap='RdYlGn', edgecolors='black', figsize=(10, 8), grid=True)\n",
    "    plt.scatter(x=sharpe_portfolio['Volatility'], y=sharpe_portfolio['Returns'], c='red', marker='D', s=200)\n",
    "    plt.scatter(x=min_variance_port['Volatility'], y=min_variance_port['Returns'], c='blue', marker='D', s=200)\n",
    "    plt.xlabel('Volatility (Std. Deviation)')\n",
    "    plt.ylabel('Expected Returns')\n",
    "    plt.title('Efficient Frontier with Tangent Portfolio')\n",
    "    plt.show()\n",
    "\n",
    "# 使用例:\n",
    "# calculate_efficient_frontier(temp_data, selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Funstion]ADF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_adf_test_on_dataframe(df, alpha=0.05):\n",
    "    # NaNの値を確認し、存在する場合はドロップ\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # 無限の値を確認し、存在する場合はNaNで置き換えてからドロップ\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    def adf_test(series):\n",
    "        # 再度、シリーズにNaNまたは無限の値がないことを確認\n",
    "        if series.isnull().sum() > 0 or np.isinf(series).sum() > 0:\n",
    "            raise ValueError(f\"Series contains NaN or infinite values\")\n",
    "            \n",
    "        result = adfuller(series, autolag='AIC')\n",
    "        test_statistic = result[0]\n",
    "        p_value = result[1]\n",
    "        lags_used = result[2]\n",
    "        nobs = result[3]\n",
    "        critical_values = result[4]\n",
    "        result_dict = {\n",
    "            \"ADF Test Statistic\": test_statistic,\n",
    "            \"P-Value\": p_value,\n",
    "            \"# Lags Used\": lags_used,\n",
    "            \"# Observations\": nobs,\n",
    "            \"Result\": \"Stationary\" if p_value <= alpha else \"Not Stationary\"\n",
    "        }\n",
    "        for key, value in critical_values.items():\n",
    "            result_dict[f'Critical Value ({key})'] = value\n",
    "        return result_dict\n",
    "    \n",
    "    results = {col: adf_test(df[col]) for col in df.columns if col != 'Date'}\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df_results = perform_adf_test_on_dataframe(df_stock_mo)\n",
    "# display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function]Deleting Stationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trend_diff(data) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply differencing and drop NaN rows to remove trend non-stationarity from time series data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pd.Series or pd.DataFrame, the input data with one or more time series columns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series or pd.DataFrame, the transformed data with trend non-stationarity removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(data, pd.Series):\n",
    "        data_copy = data.copy()\n",
    "        return data_copy.diff().dropna()\n",
    "    \n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        # List all columns except 'Date'\n",
    "        cols_to_diff = [col for col in data_copy.columns if col != 'Date']\n",
    "        \n",
    "        # Apply diff() for each column except 'Date'\n",
    "        for col in cols_to_diff:\n",
    "            data_copy[col] = data_copy[col].diff()\n",
    "        \n",
    "        # Drop rows with NaN values\n",
    "        return data_copy.dropna()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Input data must be a pandas DataFrame or Series\")\n",
    "      \n",
    "# remove_trend_diff(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function]Deliting Stationality with Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trend_log(data, selected_columns=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the log difference for a given DataFrame or Series.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pd.DataFrame or pd.Series, the input data with one or more time series columns.\n",
    "    - selected_columns: list, the columns for which the log difference should be computed.\n",
    "                    If None, it computes for all columns (except 'Date' if present).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame or pd.Series, the log difference of the original data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If data is a Series\n",
    "    if isinstance(data, pd.Series):\n",
    "        return np.log(data).diff().dropna()\n",
    "    \n",
    "    # If data is a DataFrame\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        \n",
    "        # If no specific columns are selected, select all columns except 'Date'\n",
    "        if selected_columns is None:\n",
    "            selected_columns = [col for col in data.columns if col != 'Date']\n",
    "        \n",
    "        # Apply log difference for each selected column\n",
    "        for col in selected_columns:\n",
    "            data[col] = np.log(data[col]).diff()\n",
    "        \n",
    "        return data.dropna()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Input data must be a pandas DataFrame or Series\")\n",
    "\n",
    "# Example usage\n",
    "# df_log_diff = remove_trend_log(dataframe, ['Column1', 'Column2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function]VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''---- VARモデル -----'''\n",
    "def create_var_model(data, lags=None):\n",
    "    \"\"\"\n",
    "    データフレームを入力として受け取り、指定されたラグ数でVARモデルをフィットさせる関数\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): 多変量の時系列データ\n",
    "    - lags (int, optional): モデルに使用するラグ数。指定されていない場合、自動的に選択されます。\n",
    "    \n",
    "    Returns:\n",
    "    - model: フィットされたVARモデル\n",
    "    \"\"\"\n",
    "\n",
    "    model = VAR(data)\n",
    "    \n",
    "    if lags:\n",
    "        result = model.fit(lags)\n",
    "    else:\n",
    "        result = model.fit(maxlags=12, ic='aic')  # maxlagsと情報量基準(ic)を指定して自動的にラグ数を選択\n",
    "\n",
    "    return result\n",
    "\n",
    "# 例:\n",
    "# data = pd.DataFrame({\n",
    "#     'y1': np.random.randn(100),\n",
    "#     'y2': np.random.randn(100)\n",
    "# })\n",
    "# fitted_model = create_var_model(data)\n",
    "# print(fitted_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function]Forcasting with VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''---- VARモデルでの予測 ----'''\n",
    "def plot_var_forecast_for_target(data, target='7203.T', forecast_steps=10, lags=None):\n",
    "    \"\"\"\n",
    "    VARモデルを用いて特定のターゲット変数の予測をグラフで表示する関数\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): VARモデルの入力データ\n",
    "    - target (str): 予測対象のカラム名\n",
    "    - forecast_steps (int): 予測を行うステップ数\n",
    "    \n",
    "    Returns:\n",
    "    None (グラフを表示する)\n",
    "    \"\"\"\n",
    "    \n",
    "    # VARモデルをデータに適用\n",
    "    model = VAR(data)\n",
    "    if lags:\n",
    "        fitted_model = model.fit(lags)\n",
    "    else:\n",
    "        fitted_model = model.fit(maxlags=12, ic='aic')  # maxlagsと情報量基準(ic)を指定して自動的にラグ数を選択\n",
    "    fitted_model = model.fit()\n",
    "\n",
    "    # 予測の生成\n",
    "    forecast = fitted_model.forecast(data.values[-fitted_model.k_ar:], steps=forecast_steps)\n",
    "    forecast_df = pd.DataFrame(forecast, columns=data.columns)\n",
    "\n",
    "    # 予測結果のグラフ表示\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data[target], label='Actual', color='blue')\n",
    "    plt.plot(np.arange(len(data), len(data) + forecast_steps), forecast_df[target], label='Forecast', color='red')\n",
    "    plt.title(f'Forecast for {target}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 使用例:\n",
    "# data = pd.DataFrame({\n",
    "#     '7203.T': np.random.randn(100),\n",
    "#     '7201.T': np.random.randn(100)\n",
    "# })\n",
    "# plot_var_forecast_for_target(data, target='7203.T', forecast_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## oo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
